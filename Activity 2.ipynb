{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Classification\n",
    "\n",
    "### **2019/3/22 성남-KAIST 인공지능 집중교육과정**<br/>\n",
    "<br/>\n",
    "\n",
    "***Tip> shotcuts for Jupyter Notebook***\n",
    "* Shift + Enter : run cell and select below\n",
    "\n",
    "***Library***\n",
    "* Numpy: Fundamenta package for scientific computing with Python\n",
    "* Tensorflow: An open source machine learning library for research and production\n",
    "* String : contains a number of functions to process standard Python strings(a series of characters) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import string\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_save_path = 'tmp/model.ckpt'\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data upload to Google server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_input = len(all_letters)\n",
    "n_hidden = [256, 256] # hidden layer features\n",
    "max_sequence_length = 19 # maximum number of characters is 19\n",
    "l2_lambda = 1e-4\n",
    "\n",
    "alphabet = all_letters\n",
    "ethnicities = ['Chinese', 'Japanese', 'Vietnamese', 'Korean', 'Arabic','Czech','Dutch','English','French','German','Greek','Irish','Italian','Polish','Portuguese','Russian','Scottish','Spanish']\n",
    "n_classes = len(ethnicities) # the number of classes\n",
    "\n",
    "name_strings = []\n",
    "ethnicity_strings = []\n",
    "str_list = []\n",
    "names_list = []\n",
    "ethnicity_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family name</th>\n",
       "      <th>Ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Khoury</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nahas</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daher</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gerges</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nazari</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Maalouf</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gerges</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naifeh</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Guirguis</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baba</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Family name  Ethnicity\n",
       "0      Khoury     Arabic\n",
       "1       Nahas     Arabic\n",
       "2       Daher     Arabic\n",
       "3      Gerges     Arabic\n",
       "4      Nazari     Arabic\n",
       "5     Maalouf     Arabic\n",
       "6      Gerges     Arabic\n",
       "7      Naifeh     Arabic\n",
       "8    Guirguis     Arabic\n",
       "9        Baba     Arabic"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('names_revised.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 examples for Korean family name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family name</th>\n",
       "      <th>Ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9888</th>\n",
       "      <td>Ahn</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>Baik</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>Bang</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9891</th>\n",
       "      <td>Byon</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>Cha</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9893</th>\n",
       "      <td>Chang</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9894</th>\n",
       "      <td>Chi</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9895</th>\n",
       "      <td>Chin</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9896</th>\n",
       "      <td>Cho</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9897</th>\n",
       "      <td>Choe</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Family name  Ethnicity\n",
       "9888         Ahn     Korean\n",
       "9889        Baik     Korean\n",
       "9890        Bang     Korean\n",
       "9891        Byon     Korean\n",
       "9892         Cha     Korean\n",
       "9893       Chang     Korean\n",
       "9894         Chi     Korean\n",
       "9895        Chin     Korean\n",
       "9896         Cho     Korean\n",
       "9897        Choe     Korean"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.where(data.loc[:, [' Ethnicity']] == 'Korean')\n",
    "kor = data.loc[ids[0], :]\n",
    "kor.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding to One-hot vectors\n",
    "'a' is converted to a vector [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]<br/>\n",
    "For example, 'Ahn' is converted to\n",
    "<img src='./figure%201.png' width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_one_hot(name, max_sequence_length):\n",
    "    result = []\n",
    "    for char in name:\n",
    "        v = np.zeros(n_input, dtype=np.int) # count space as a character\n",
    "        v[alphabet.index(char)] = 1\n",
    "        result.append(v)\n",
    "    while len(result) < max_sequence_length:\n",
    "        result.append(np.zeros(n_input, dtype=np.int))\n",
    "    result = np.array(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ethnicity_one_hot(ethnicity):\n",
    "    v = np.zeros(n_classes, dtype=np.int)\n",
    "    v[ethnicities.index(ethnicity)] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in zip(data['Family name'], data[' Ethnicity']):\n",
    "    if(line[1] in ethnicities):\n",
    "        name_strings.append(line[0])\n",
    "        ethnicity_strings.append(line[1])\n",
    "        if len(line[0]) > max_sequence_length:\n",
    "            line[0] = line[0][:max_sequence_length]\n",
    "        names_list.append(name_one_hot(line[0], max_sequence_length)) # one-hot vector of each characters of name\n",
    "        ethnicity_list.append(ethnicity_one_hot(line[1]))             # one-hot vector of ethnicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training - Test Seperation\n",
    "Split the data for training and test with 9:1 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_state = np.random.get_state() # use the same random number generator state\n",
    "np.random.shuffle(names_list)     # when shuffling the two lists\n",
    "np.random.set_state(rng_state)    # they are effectively shuffled in parallel so that inputs still correspond to outputs after shuffling\n",
    "np.random.shuffle(ethnicity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(names_list) \n",
    "train_size = int(size*0.9) \n",
    "\n",
    "training_X = np.array(names_list[:train_size])\n",
    "training_y = np.array(ethnicity_list[:train_size])\n",
    "testing_X = np.array(names_list[train_size:])\n",
    "testing_y = np.array(ethnicity_list[train_size:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Test set examples for Korean\n",
      "\n",
      "Ma\n",
      "\n",
      "Chu\n",
      "\n",
      "Choe\n",
      "\n",
      "Gwang \n",
      "\n",
      "Youj\n",
      "\n",
      "Lee\n",
      "\n",
      "Kwak\n",
      "\n",
      "Oh \n",
      "\n",
      "Chi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[*] Test set examples for Korean\\n\")\n",
    "for name, nation in zip(testing_X, testing_y):\n",
    "    if np.where(nation)[0] == 3:\n",
    "        for char in name:\n",
    "            if np.size(np.where(char)[0]) > 0:\n",
    "                print(alphabet[np.where(char)[0][0]], end='')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, max_sequence_length, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>DNN structure (<span style=\"color:red\">Fill in the blanks</span>)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = tf.reshape(X, [-1, max_sequence_length * n_input])\n",
    "\n",
    "w_init = tf.variance_scaling_initializer()\n",
    "b_init = tf.constant_initializer(0.)\n",
    "\n",
    "## 1st hidden layer\n",
    "w1 =                                # weight for 1st hidden layer which have 256 units\n",
    "b1 =                                # bias for 1st hidden layer which have 256 units\n",
    "h  =                                # matrix multiplication\n",
    "h  =                                # relu activation\n",
    "\n",
    "## 2nd hidden layer\n",
    "w2 =                                # weight for 2nd hidden layer which have 256 units\n",
    "b2 =                                # bias for 2nd hidden layer which have 256 units\n",
    "h  =                                # matrix multiplication\n",
    "h  =                                # relu activation\n",
    "\n",
    "## output layer\n",
    "w3 =                                # weight for output layer which have 256 units\n",
    "\n",
    "y_pred = tf.matmul(h, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cent = tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_pred, labels=y)\n",
    "loss = tf.reduce_mean(cent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_var = [var for var in tf.trainable_variables() ]\n",
    "l2_losses = []\n",
    "for var in all_var:\n",
    "    if var.op.name.find('weight') == 0:\n",
    "        l2_losses.append(tf.nn.l2_loss(var))\n",
    "\n",
    "reg_losses = loss + _l2_lambda * tf.reduce_sum(l2_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Momentum optimizer (<span style=\"color:red\">Fill in the blanks</span>)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step =                                           # Momentum optimizer with momentum 0.9 to minimize \"reg_loss\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation\n",
    "correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "## Softmax\n",
    "pred = tf.nn.softmax(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAKE SESSION\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "## INITIALIZE SESSION\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "## Saver\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_epoch = 500\n",
    "start_time = time.time()\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epoch+1):\n",
    "    _, avg_loss = sess.run([train_step, loss], feed_dict={X: training_X, y: training_y})\n",
    "    losses.append(avg_loss)\n",
    "    \n",
    "    if epoch%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={X:training_X, y:training_y})\n",
    "        test_accuracy = accuracy.eval(feed_dict={X:testing_X, y:testing_y})\n",
    "        current_time = time.time() - start_time\n",
    "        print(\"[*] Step %d, Training accuracy %.4f // Testing accuracy %.4f // Time: %3.2f\"%(epoch, train_accuracy, test_accuracy, current_time))\n",
    "        \n",
    "saver.save(sess, model_save_path)\n",
    "print(\"Model saved in file: %s\" % model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title(\"Learning curve\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Epochs\", fontsize=14, fontweight='bold')\n",
    "plt.ylabel(\"RMSE of training set\", fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type 5 last names for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "while i<5:\n",
    "    input_name = input('Enter a last name (max 19 letters):')\n",
    "   \n",
    "    while len(input_name) > max_sequence_length or len(input_name) == 0:\n",
    "        input_name = raw_input('Invalid input. Enter a last name (max 19 letters):')\n",
    "   \n",
    "    result=pred.eval(feed_dict={X: np.expand_dims(name_one_hot(input_name, 19), axis=0)})[0]\n",
    "    idx = np.argsort(result)[::-1]\n",
    "    print(\"\\n(%s): %.4f\" % (ethnicities[idx[0]], result[idx[0]]))\n",
    "    print(\"(%s): %.4f\" % (ethnicities[idx[1]], result[idx[1]]))\n",
    "    print(\"(%s): %.4f\" % (ethnicities[idx[2]], result[idx[2]]))\n",
    "    print(\"==========================================\")\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_parameters = 0\n",
    "for var in tf.trainable_variables():\n",
    "    n_parameters += tf.size(var)\n",
    "n_dnn = sess.run(n_parameters)\n",
    "print(\"The number of parameters %d\" % sess.run(n_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Report\n",
    "### 1. Fill in the blank code\n",
    "Design a DNN model with 2 hidden layers which have 256 units. Minimize the loss function using Momentum optimizer with momenum 0.9.\n",
    "\n",
    "### 2. Adam Optimizer\n",
    "Use the \"Adam Optimizer( )\" instead of the MomentumOptimizer and compare the RMSE learning curves of the two optimizers.\n",
    "<br>\n",
    "*Hint)* tf.train.AdamOptimizer( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
